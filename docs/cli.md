# 🧠 CLI

`playground` CLI is available in `scripts/cli/playground`.
It makes so much easier to use the playground and reduces a lot the Docker knowledge required !

## 🚜 Setup

### 🦶 Setup PATH

Add it to your `PATH` environment variable by adding this in your `~/.bashrc` or `~/.zshrc`:

```bash
export PATH=/path/to/kafka-docker-playground/scripts/cli:$PATH
```

> [!WARNING]
> The bash script generated by [bashly](https://bashly.dannyb.co/) can run in any shell, but require that bash 4 or higher is installed.
> Mac users can upgrade bash by running `brew install bash`

### ⚡ Setup completion

A Bash completion file is also available in `scripts/cli/completions.bash`.

In order to be able to use completion with the CLI, you just need to add this in your `~/.bashrc` or `~/.zshrc`:

```bash
source /path/to/kafka-docker-playground/scripts/cli/completions.bash
```

> [!NOTE]
> If you use ZSH, but **not** `Oh-My-Zsh`, please check [this](https://bashly.dannyb.co/advanced/bash-completion/#completions-in-zsh).

### ⚙️ Config file 

CLI can be configured using `config.ini` [file](https://github.com/vdesabou/kafka-docker-playground/blob/master/scripts/cli/config.ini)

```ini
;; Configuration file for playground CLI

;; You can configure the path to your config.ini file using CONFIG_FILE environment variable
;; export CONFIG_FILE="path/to/config.ini"

; editor to use to open files
editor = code

; list (comma separated) of folders where to search for zip or jar
; Current folder is always included
; examples:
; folder_zip_or_jar = ~/Downloads,~/Documents/github/kafka-connect-*
folder_zip_or_jar = ~/Downloads
```

You can configure the path to your own config.ini file using `CONFIG_FILE` environment variable:

```bash
export CONFIG_FILE="/path/to/config.ini"
```

## 🚀 Run commands

### 🕹️ `run`

Run any example, except for Confluent Cloud (in this case use `run-ccloud` command) from anywhere using all the possible options available!

> [!WARNING]
> The `run` command requires to have [fzf](https://github.com/junegunn/fzf) installed, it can easily be installed with `brew install fzf` on Mac.

> [!TIP]
> [bat](https://github.com/sharkdp/bat) is also used by `run` command to display files with syntax highlighting and colors, you can install it using `brew install bat` on Mac.


<script async id="asciicast-581275" src="https://asciinema.org/a/581275.js" async data-autoplay="true" data-size="big"></script>


```bash
$ playground run - 🕹️ Run any example, except for Confluent Cloud (in this case use run-ccloud command)

== Usage ==
  playground run [OPTIONS] [ARGUMENTS...]
  playground run --help | -h

== Options ==
  --file, -f FILE (required)
    🔖 Example file to run
    
    ❕ It must be absolute full path
    
    🎓 Tip: use <tab> completion to trigger fzf completion

  --open, -o
    📖 Opening example file with text editor set with config.ini (default is
    code)

  --tag TAG
    🎯 Confluent Platform (CP) version to use
    
    Must be greater or equal to 5.0.0

  --connector-tag CONNECTOR_TAG
    🔗 Connector version to use
    
    By default, for each connector, the latest available version on Confluent
    Hub is used

  --connector-zip CONNECTOR_ZIP
    🤐 Connector zip to use
    
    ❕ It must be absolute full path
    
    🎓 Tip: use <tab> completion to trigger fzf completion 
            use folder_zip_or_jar (default: ~/Downloads) in config.ini file to
    configure where to search the files (current folder is always used)

  --connector-jar CONNECTOR_JAR
    ♨️ Connector jar to use
    
    ❕ It must be absolute full path
    
    🎓 Tip: use <tab> completion to trigger fzf completion 
            use folder_zip_or_jar (default: ~/Downloads) in config.ini file to
    configure where to search the files (current folder is always used)

  --enable-ksqldb
    🚀 Enable ksqlDB
    
    By default, ksqldb-server and ksqldb-cli containers are not started for
    every test

  --enable-control-center
    💠 Enable Control Center
    
    By default, control-center container is not started for every test
    
    Control Center is reachable at http://127.0.0.1:9021

  --enable-conduktor
    🐺 Enable Conduktor Platform
    
    By default, Conduktor Platform container is not started for every test
    
    Conduktor is reachable at http://127.0.0.1:8080/console (admin/admin)

  --enable-multiple-brokers
    3️⃣ Enable multiple brokers
    
    By default, there is only one broker node enabled

  --enable-multiple-connect-workers
    🥉 Enable multiple connect node
    
    By default, there is only one connect node enabled
    
    It only works when plaintext environment is used

  --enable-jmx-grafana
    Enable Grafana, Prometheus and Pyroscope
    
    📊 Grafana is reachable at http://127.0.0.1:3000
    🛡️ Prometheus is reachable at http://127.0.0.1:9090
    📛 Pyroscope is reachable at http://127.0.0.1:4040

  --enable-kcat
    🐈‍⬛ Enable kcat
    
    You can use it with:
    
    $ docker exec kcat kcat -b broker:9092 -L

  --enable-sr-maven-plugin-app
    🔰 Enable Schema Registry Maven plugin App

  --enable-sql-datagen
    🌪️ Enable SQL Datagen injection
    
    This only works for Oracle, MySql, Postgres and Microsoft Sql Server source
    connector examples with JDBC and Debezium

  --help, -h
    Show this help

== Arguments ==
  ARGUMENTS...
    Arguments to use by example script
    
    Most of examples support to get required options either by using arguments
    or environment variables.
    
    Example with Zendesk:
    
    playground run -f zendesk-source<tab> <ZENDESK_URL> <ZENDESK_USERNAME>
    <ZENDESK_PASSWORD>

Examples
  playground run -f zendesk-source<tab> --tag 7.2.1 --enable-control-center
  <ZENDESK_URL> <ZENDESK_USERNAME> <ZENDESK_PASSWORD>
  playground run -f jdbc<tab> --connector-tag 10.6.0 --enable-jmx-grafana --open
```

### ⛅ `run-ccloud`

Run any Confluent Cloud (ccloud) example from anywhere using all the possible options available!




```bash
$ playground run-ccloud --help
playground run-ccloud

  ⛅ Run any Confluent Cloud (ccloud) example
  
  All you have to do is to be already logged in with confluent CLI.
  
  By default, a new Confluent Cloud environment with a Cluster will be created.
  
  You can configure the new cluster by setting:
  
  --cluster-cloud (or CLUSTER_CLOUD environment variable)
  --cluster-region (or CLUSTER_REGION environment variable)
  --cluster-environment (or ENVIRONMENT environment variable)
  
  In case you want to use your own existing cluster, you need to setup, in
  addition to previous ones:
  
  --cluster-name (or CLUSTER_NAME environment variable)
  --cluster-creds (or CLUSTER_CREDS environment variable)
  --cluster-schema-registry-creds (or SCHEMA_REGISTRY_CREDS environment
  variable)

== Usage ==
  playground run-ccloud [OPTIONS] [ARGUMENTS...]
  playground run-ccloud --help | -h

== Options ==
  --file, -f FILE (required)
    🔖 Example file to run
    
    ❕ It must be absolute full path
    
    🎓 Tip: use <tab> completion to trigger fzf completion

  --open, -o
    📖 Opening example file with text editor set with config.ini (default is
    code)

  --tag TAG
    🎯 Confluent Platform (CP) version to use
    
    Must be greater or equal to 5.0.0

  --connector-tag CONNECTOR_TAG
    🔗 Connector version to use
    
    By default, for each connector, the latest available version on Confluent
    Hub is used

  --connector-zip CONNECTOR_ZIP
    🤐 Connector zip to use
    
    ❕ It must be absolute full path
    
    🎓 Tip: use <tab> completion to trigger fzf completion 
            use folder_zip_or_jar (default: ~/Downloads) in config.ini file to
    configure where to search the files (current folder is always used)

  --connector-jar CONNECTOR_JAR
    ♨️ Connector jar to use
    
    ❕ It must be absolute full path
    
    🎓 Tip: use <tab> completion to trigger fzf completion 
            use folder_zip_or_jar (default: ~/Downloads) in config.ini file to
    configure where to search the files (current folder is always used)

  --enable-control-center
    💠 Enable Control Center
    
    By default, control-center container is not started for every test
    
    Control Center is reachable at http://127.0.0.1:9021

  --enable-conduktor
    🐺 Enable Conduktor Platform
    
    By default, Conduktor Platform container is not started for every test
    
    Conduktor is reachable at http://127.0.0.1:8080/console (admin/admin)

  --enable-kcat
    🐈‍⬛ Enable kcat
    
    You can use it with:
    
    $ docker exec kcat kcat -b broker:9092 -L

  --cluster-cloud CLUSTER-CLOUD
    🌤 The cloud provider: aws, gcp or azure. Default is aws
    
    🎓 Tip: you can also use CLUSTER_CLOUD environment variable
    Allowed: aws, gcp, azure
    Default: aws

  --cluster-region CLUSTER-REGION
    🗺 The Cloud region. 
    
    🎓 Tip: you can also use CLUSTER_REGION environment variable
    Default: eu-west-2

  --cluster-environment CLUSTER-ENVIRONMENT
    🌐 The environment id where want your new cluster (example: env-xxxxx)
    
    ℹ️ Optional, if not set, new environment will be created
    
    🎓 Tip: you can also use ENVIRONMENT environment variable

  --cluster-name CLUSTER-NAME
    🎰 The cluster name. 
    
    ❣️ Only required if you want to use your own existing cluster
    
    🎓 Tip: you can also use CLUSTER_NAME environment variable

  --cluster-creds CLUSTER-CREDS
    🔒 The Kafka api key and secret to use, it should be separated with
    semi-colon (example: <API_KEY>:<API_KEY_SECRET>)
    
    ❣️ Only required if you want to use your own existing cluster
    
    🎓 Tip: you can also use CLUSTER_CREDS environment variable

  --cluster-schema-registry-creds CLUSTER-SCHEMA-REGISTRY-CREDS
    🔒 The Schema Registry api key and secret to use, it should be separated with
    semi-colon (example: <SR_API_KEY>:<SR_API_KEY_SECRET>)
    
    ℹ️ Optional, if not set, new credentials will be created
    
    ❣️ Only required if you want to use your own existing cluster
    
    🎓 Tip: you can also use SCHEMA_REGISTRY_CREDS environment variable

  --help, -h
    Show this help

== Arguments ==
  ARGUMENTS...
    Arguments to use by example script
    
    Most of examples support to get required options either by using arguments
    or environment variables.
    
    Example with Zendesk:
    
    playground run -f zendesk-source<tab> <ZENDESK_URL> <ZENDESK_USERNAME>
    <ZENDESK_PASSWORD>

Examples
  playground run-ccloud mqtt<tab> --cluster-cloud aws --cluster-region eu-west-3
  --enable-control-center --connector-tag 1.2.3
```

### ⚡ `re-run`

Simply re-run last example you ran with `run` [command](/cli?id=%f0%9f%95%b9%ef%b8%8f-run) !

If you don't specify any flags, it will re-run with same flags as before.

Examples:

```bash
$ playground re-run

# will re-run same example:
$ playground run -f /path/to/kafka-docker-playground/connect/connect-jdbc-postgresql-sink/postgres-sink.sh --tag=7.3.3 --connector-tag=10.6.0 --disable-control-center
```

```bash
$ playground re-run --connector-tag=10.6.1

# will re-run same example but replace previous flags with:
$ playground run -f /path/to/kafka-docker-playground/connect/connect-jdbc-postgresql-sink/postgres-sink.sh --connector-tag=10.6.1
```

<script async id="asciicast-581276" src="https://asciinema.org/a/581276.js"></script>

```bash
$ playground re-run --help
playground re-run - ⚡ Simply re-run last example you ran with <playground run> or <playground run-ccloud>

== Usage ==
  playground re-run [OPTIONS] [ARGUMENTS...]
  playground re-run --help | -h

== Options ==
  --tag TAG
    🎯 Confluent Platform (CP) version to use
    
    Must be greater or equal to 5.0.0

  --connector-tag CONNECTOR_TAG
    🔗 Connector version to use
    
    By default, for each connector, the latest available version on Confluent
    Hub is used

  --connector-zip CONNECTOR_ZIP
    🤐 Connector zip to use
    
    ❕ It must be absolute full path
    
    🎓 Tip: use <tab> completion to trigger fzf completion 
            use folder_zip_or_jar (default: ~/Downloads) in config.ini file to
    configure where to search the files (current folder is always used)

  --connector-jar CONNECTOR_JAR
    ♨️ Connector jar to use
    
    ❕ It must be absolute full path
    
    🎓 Tip: use <tab> completion to trigger fzf completion 
            use folder_zip_or_jar (default: ~/Downloads) in config.ini file to
    configure where to search the files (current folder is always used)

  --enable-ksqldb
    🚀 Enable ksqlDB
    
    By default, ksqldb-server and ksqldb-cli containers are not started for
    every test

  --enable-control-center
    💠 Enable Control Center
    
    By default, control-center container is not started for every test
    
    Control Center is reachable at http://127.0.0.1:9021

  --enable-conduktor
    🐺 Enable Conduktor Platform
    
    By default, Conduktor Platform container is not started for every test
    
    Conduktor is reachable at http://127.0.0.1:8080/console (admin/admin)

  --enable-multiple-brokers
    3️⃣ Enable multiple brokers
    
    By default, there is only one broker node enabled

  --enable-multiple-connect-workers
    🥉 Enable multiple connect node
    
    By default, there is only one connect node enabled
    
    It only works when plaintext environment is used

  --enable-jmx-grafana
    Enable Grafana, Prometheus and Pyroscope
    
    📊 Grafana is reachable at http://127.0.0.1:3000
    🛡️ Prometheus is reachable at http://127.0.0.1:9090
    📛 Pyroscope is reachable at http://127.0.0.1:4040

  --enable-kcat
    🐈‍⬛ Enable kcat
    
    You can use it with:
    
    $ docker exec kcat kcat -b broker:9092 -L

  --enable-sr-maven-plugin-app
    🔰 Enable Schema Registry Maven plugin App

  --enable-sql-datagen
    🌪️ Enable SQL Datagen injection
    
    This only works for Oracle, MySql, Postgres and Microsoft Sql Server source
    connector examples with JDBC and Debezium

  --help, -h
    Show this help

== Arguments ==
  ARGUMENTS...
    Arguments to use by example script
    
    Most of examples support to get required options either by using arguments
    or environment variables.
    
    Example with Zendesk:
    
    playground run -f zendesk-source<tab> <ZENDESK_URL> <ZENDESK_USERNAME>
    <ZENDESK_PASSWORD>

Examples
  playground re-run
  playground re-run --tag=6.2.1
```

### 👐 `open`

Simply open last example you ran with `run` [command](/cli?id=%f0%9f%95%b9%ef%b8%8f-run) in your configured editor (see `editor` config in [⚙️ Config file](/cli?id=%e2%9a%99%ef%b8%8f-config-file), default is code).

### 🛑 `stop`

Stop currently running example.




<script async id="asciicast-581277" src="https://asciinema.org/a/581277.js"></script>

```bash
playground open --help
playground open - 👐 Simply open last example you ran with <playground run>

== Usage ==
  playground open
  playground open --help | -h

== Options ==
  --help, -h
    Show this help

```

## 👷 Bootstrap commands

Build your own example or reproduction model !

### 🛠 `bootstrap-reproduction-model`

Bootstrap reproduction model. See documentation [here](/reusables?id=%f0%9f%9b%a0-bootstrap-reproduction-model).

## 🔗 Connector commands

Easily interact with running connectors.

The `connector` command applies for all *onprem* and *self-managed* examples.

⛅ For *fully-managed* connector examples, the command is named `ccloud-connector`.

### 🧑‍🎨 `create-or-update`

Example:

```bash
playground connector create-or-update -c filestream-sink << EOF
{
    "tasks.max": "1",
    "connector.class": "org.apache.kafka.connect.file.FileStreamSinkConnector",
    "topics": "filestream",
    "file": "/tmp/output.json",
    "key.converter": "org.apache.kafka.connect.storage.StringConverter",
    "value.converter": "org.apache.kafka.connect.json.JsonConverter",
    "value.converter.schemas.enable": "false"
}
EOF
22:19:57 ℹ️ 🛠️ Creating connector filestream-sink
22:19:57 ℹ️ ✅ Connector filestream-sink was successfully created
22:19:57 ℹ️ 🥁 Waiting a few seconds to get new status
22:20:06 ℹ️ 🧩 Displaying connector status
Name                           Status       Tasks                                                        Stack Trace                                       
-----------------------------------------------------------------------------------------------------------------------------
filestream-sink                ✅ RUNNING  0:🟢 RUNNING[connect]        - 
```

### 🧩 `status`

Show status of all connectors

<script async id="asciicast-581278" src="https://asciinema.org/a/581278.js"></script>

### 🎨 `plugins`

Show all plugins installed

<script async id="asciicast-581279" src="https://asciinema.org/a/581279.js"></script>

### ⏸️ `pause`

Pause connector

<script async id="asciicast-581280" src="https://asciinema.org/a/581280.js"></script>

> [!TIP]
> If flag `--connector` (`-c`) is not specified, the command will apply to all connectors.

### ⏯️ `resume`

Resume connector

<script async id="asciicast-581281" src="https://asciinema.org/a/581281.js"></script>

> [!TIP]
> If flag `--connector` (`-c`) is not specified, the command will apply to all connectors.

### 🧞 `versions`

Get current and latest version available on Confluent Hub for connector(s) used in example

Example:

```bash
15:36:21 ℹ️ 🗯️ Version currently used for confluentinc-kafka-connect-jdbc is not latest
15:36:21 ℹ️ Current
"🔢 v5.5.0 - 📅 release date: 2020-04-22"
15:36:21 ℹ️ Latest on Hub
"🔢 v10.7.2 - 📅 release date: 2023-05-29"
```

> [!TIP]
> If flag `--connector` (`-c`) is not specified, the command will apply to all connectors.

### ♻️ `restart`

Restart connector(s)

<script async id="asciicast-581284" src="https://asciinema.org/a/581284.js"></script>

> [!TIP]
> If flag `--connector` (`-c`) is not specified, the command will apply to all connectors.

### 🗑️ `delete`

Delete connector

<script async id="asciicast-581288" src="https://asciinema.org/a/581288.js"></script>

> [!TIP]
> If flag `--connector` (`-c`) is not specified, the command will apply to all connectors.

### 🐢 `show-lag`

Show lag of sink connector

<script async id="asciicast-581285" src="https://asciinema.org/a/581285.js"></script>

> [!TIP]
> If flag `--connector` (`-c`) is not specified, the command will apply to all connectors.

### 🧬 `log-level`

Set connect log level

<script async id="asciicast-581287" src="https://asciinema.org/a/581287.js"></script>

> [!TIP]
> If flag `--connector` (`-c`) is not specified, the command will apply to all connectors.

## 📦 Container commands

Easily interact with running docker containers.

### 💫 `recreate`

Recreate container(s). See documentation [there](/how-to-use?id=%e2%99%bb%ef%b8%8f-re-create-containers)

### 🖥️ `get-ip-addresses`

Get ip address of running containers

<script async id="asciicast-581364" src="https://asciinema.org/a/581364.js"></script>

### 🕵️ `logs`

Tail and follow container logs

```bash
playground container logs --help    
playground container logs - 🕵️  Tail and follow container logs

== Usage ==
  playground container logs [OPTIONS]
  playground container logs --help | -h

== Options ==
  --container, -c CONTAINER
    🐳 Container name
    Default: connect

  --open, -o
    🔖 Save output to a file and open with text editor set with config.ini
    (default is code)

  --wait-for-log, -w LOG
    😴 Wait until log appears

  --max-wait, -m MAX_WAIT
    ⏳ Max time in seconds to wait when using --wait-for-log (default 600s)
    Default: 600

  --help, -h
    Show this help

Examples
  playground container logs --container connect
  playground container logs -c connect --open
  playground container logs -c connect --wait-for-log "StackOverflowError"
```

### 🛬 `ssh`

SSH into container

<script async id="asciicast-581366" src="https://asciinema.org/a/581366.js"></script>

```bash
$ playground container ssh --help
playground container ssh - 🛬 SSH into container

== Usage ==
  playground container ssh [OPTIONS]
  playground container ssh --help | -h

== Options ==
  --container, -c CONTAINER
    🐳 Container name
    Default: connect

  --shell, -s SHELL
    💾 Shell to use (default is bash)
    Allowed: bash, sh, ksh, zsh
    Default: bash

  --help, -h
    Show this help

Examples
  playground ssh -c connect
  playground ssh -c connect -s sh
  playground ssh --container connect --shell sh
```

> [!TIP]
> If flag `--container` (`-c`) is not specified, the command will apply to `connect` container.

### 🪄 `exec`

Execute command in a container

<script async id="asciicast-581367" src="https://asciinema.org/a/581367.js"></script>

```bash
$ playground container exec --help                                        
playground container exec - 🪄  Execute command in a container

== Usage ==
  playground container exec [OPTIONS]
  playground container exec --help | -h

== Options ==
  --container, -c CONTAINER
    🐳 Container name
    Default: connect

  --command COMMAND (required)
    📲 Command to execute

  --root
    👑 Run command as root

  --shell SHELL
    💾 Shell to use (default is bash)
    Allowed: bash, sh, ksh, zsh
    Default: bash

  --help, -h
    Show this help

Examples
  playground exec -c connect -d "date"
  playground exec -c connect -d "whoami" --root
  playground exec --container connect --command "whoami" --shell sh
```

> [!TIP]
> If flag `--container` (`-c`) is not specified, the command will apply to `connect` container.

### 🔁 `restart`

Restart a container

<script async id="asciicast-581368" src="https://asciinema.org/a/581368.js"></script>

### ⏸️ `pause`

Pause a container

<script async id="asciicast-581369" src="https://asciinema.org/a/581369.js"></script>

### ⏯️ `resume`

Resume a container

<script async id="asciicast-581584" src="https://asciinema.org/a/581584.js"></script>

### 🔫 `kill`

Kill a container

<script async id="asciicast-581586" src="https://asciinema.org/a/581586.js"></script>

### 💀 `kill-all`

Kill all containers

<script async id="asciicast-581587" src="https://asciinema.org/a/581587.js"></script>

## 🗳 Topics commands

Easily interact with kafka topics.

### 📥 `produce`

💫 Magically produce to topic.

🔥 You can either:

1. Set your own schema (avro, json-schema, protobuf) with *stdin* (`<< 'EOF'`)

<!-- tabs:start -->

#### **json-schema**

```bash
$ playground topic produce -t topic-json-schema --nb-messages 3 << 'EOF'
{
  "$schema": "http://json-schema.org/draft-07/schema#",
  "additionalProperties": false,
  "$id": "http://lh.test/Customer.schema.json",
  "title": "Customer",
  "description": "Customer description",
  "type": "object",
  "properties": {
    "name": {
      "description": "Customer name",
      "type": "string",
      "maxLength": 25
    },
    "surname": {
      "description": "Customer surname",
      "type": "string",
      "minLength": 2
    },
    "email": {
      "description": "Email",
      "type": "string",
      "pattern": "^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+$"
    }
  },
  "required": [
    "name",
    "surname"
  ]
}
EOF

21:41:18 ℹ️ 🔮 schema was identified as json schema
21:41:18 ℹ️ ✨ 3 records were generated
{"name":"deserunt est in anim pr","surname":"enim dolore sunt","email":"j7B@u89Gm.a66LQ"}
{"name":"","surname":"in Excepteur fugiat dolor","email":"o@DvfTGuIA.qIwtqrzo"}
{"name":"do","surname":"id dolore","email":"woRlT@mA4pdr9eG2.m"}
21:41:20 ❗ topic topic-json-schema does not exist !
21:41:20 ℹ️ 📤 producing 3 records to topic topic-json-schema
[2023-06-12 19:41:22,385] WARN [Producer clientId=console-producer] Error while fetching metadata with correlation id 4 : {topic-json-schema=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient)
21:41:23 ℹ️ 💯 Get number of records in topic topic-json-schema
3
```

#### **avro**

```bash
$ playground topic produce -t topic-avro --nb-messages 1 << 'EOF'
{
    "type": "record",
    "namespace": "com.github.vdesabou",
    "name": "Customer",
    "fields": [
        {
            "name": "count",
            "type": "long",
            "doc": "count"
        },
        {
            "name": "first_name",
            "type": "string",
            "doc": "First Name of Customer"
        },
        {
            "name": "last_name",
            "type": "string",
            "doc": "Last Name of Customer"
        },
        {
            "name": "address",
            "type": "string",
            "doc": "Address of Customer"
        }
    ]
}
EOF
```

#### **protobuf**

```bash
$ playground topic produce -t topic-proto --nb-messages 10 << 'EOF'
syntax = "proto3";

message Order {
  float         total = 1;
  repeated Item items = 2;

  message Item {
    string name  = 1;
    float  price = 2;
  }
}
EOF
```

<!-- tabs:end -->

2. You can also generate json data using json or sql format using syntax from [MaterializeInc/datagen](https://github.com/MaterializeInc/datagen)


<!-- tabs:start -->
#### **json**


```bash
$ playground topic produce -t topic-json --nb-messages 5 << 'EOF'
[
    {
        "_meta": {
            "topic": "",
            "key": "",
            "relationships": [
            ]
        },
        "nested": {
            "phone": "faker.phone.imei()",
            "website": "faker.internet.domainName()"
        },
        "id": "iteration.index",
        "name": "faker.internet.userName()",
        "email": "faker.internet.exampleEmail()",
        "phone": "faker.phone.imei()",
        "website": "faker.internet.domainName()",
        "city": "faker.address.city()",
        "company": "faker.company.name()"
    }
]
EOF
21:53:06 ℹ️ 🔮 schema was identified as json
21:53:07 ℹ️ ✨ 5 records were generated
{"nested":{"phone":"33-782181-043799-9","website":"insubstantial-tomato.info"},"id":1,"name":"Amos.Nitzsche","email":"Emmanuelle23@example.com","phone":"00-112159-149949-9","website":"outstanding-hydrant.net","city":"North
{"nested":{"phone":"30-226290-881807-4","website":"charming-ant.info"},"id":2,"name":"Michael33","email":"Litzy_Feil@example.net","phone":"66-855187-415752-7","website":"accurate-deputy.biz","city":"Jonesboro","company":"Satterfield
{"nested":{"phone":"70-808242-265994-9","website":"untrue-indicator.net"},"id":3,"name":"Emmy.Barrows7","email":"Laurine65@example.org","phone":"31-815588-513073-1","website":"responsible-soap.net","city":"South
{"nested":{"phone":"02-314544-912274-2","website":"thoughtful-settler.info"},"id":4,"name":"Santos.Hoppe86","email":"Jarrett8@example.net","phone":"04-582921-373278-6","website":"immaculate-nerve.net","city":"Wolffcester","company":"Jacobs
{"nested":{"phone":"52-898377-349339-0","website":"clean-hybridization.info"},"id":5,"name":"Davonte_Gleichner72","email":"Adell.Schmitt@example.org","phone":"06-356015-789964-9","website":"scary-protein.org","city":"Missouri
21:53:10 ❗ topic topic-json does not exist !
21:53:10 ℹ️ 📤 producing 5 records to topic topic-json
[2023-06-12 19:53:12,117] WARN [Producer clientId=console-producer] Error while fetching metadata with correlation id 1 : {topic-json=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient)
21:53:12 ℹ️ 💯 Get number of records in topic topic-json
5
```

#### **sql**


```bash
$ playground topic produce -t topic-json-sql --nb-messages 10 << 'EOF'
CREATE TABLE "notused"."notused" (
  "id" int PRIMARY KEY,
  "name" varchar COMMENT 'faker.internet.userName()',
  "merchant_id" int NOT NULL COMMENT 'faker.datatype.number()',
  "price" int COMMENT 'faker.datatype.number()',
  "status" int COMMENT 'faker.datatype.boolean()',
  "created_at" datetime DEFAULT (now())
);
EOF
21:53:58 ℹ️ 🔮 schema was identified as sql
21:53:59 ℹ️ ✨ 10 records were generated (only showing first 10)
{"id":59126,"name":"Diana89","merchant_id":16039,"price":82506,"status":true,"created_at":"IM*gyUS%AK"}
{"id":58849,"name":"Drake5","merchant_id":56477,"price":60429,"status":true,"created_at":"dO?KiiMbTA"}
{"id":72877,"name":"Itzel_Kling","merchant_id":40582,"price":55787,"status":false,"created_at":"E3.9Zv@oy("}
{"id":34161,"name":"Orland.Hoppe31","merchant_id":49733,"price":36431,"status":false,"created_at":"gP^y*\"A=vO"}
{"id":3877,"name":"Kamryn.Raynor","merchant_id":33305,"price":56642,"status":false,"created_at":"G=Wv>ag0Fw"}
{"id":46320,"name":"Mitchell_Bednar","merchant_id":68132,"price":96747,"status":true,"created_at":"#e{tBT`^y<"}
{"id":41523,"name":"Freda.Oberbrunner","merchant_id":29066,"price":29099,"status":true,"created_at":"+SXnJ';;<H"}
{"id":57987,"name":"Dedrick_Erdman97","merchant_id":24643,"price":9425,"status":false,"created_at":"R|KEb,B^$O"}
{"id":98803,"name":"Geovany.Skiles","merchant_id":48406,"price":77861,"status":false,"created_at":"xy:5R9B6V3"}
{"id":56777,"name":"Isabella.Ziemann88","merchant_id":44384,"price":54554,"status":true,"created_at":"x>9K.4te/q"}
21:54:02 ❗ topic topic-json-sql does not exist !
21:54:02 ℹ️ 📤 producing 10 records to topic topic-json-sql
[2023-06-12 19:54:03,425] WARN [Producer clientId=console-producer] Error while fetching metadata with correlation id 1 : {topic-json-sql=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient)
21:54:04 ℹ️ 💯 Get number of records in topic topic-json-sql
10
```
<!-- tabs:end -->

3. Use `fzf` completion (use `--input` and then <tab>) to select predefined schemas or your own schemas (`.avsc`, `proto`, `proto5`, `sql` or `json` file should be within subfolders where command is started)

See example:

[![asciicast](https://asciinema.org/a/591076.svg)](https://asciinema.org/a/591076)

4. and much more

<!-- tabs:start -->

#### **json with schema**

```bash
$ playground topic produce -t topic-json-with-schema --nb-messages 10 << 'EOF'
{
  "schema": {
    "type": "struct",
    "fields": [
      {
        "type": "string",
        "optional": false,
        "field": "record"
      }
    ]
  },
  "payload": {
    "record": "cdcd"
  }
}
EOF
22:08:24 ℹ️ 📢 no known schema could be identified, payload will be sent as raw data
22:08:24 ℹ️ 💫 payload is single json, it will be sent as one record
22:08:24 ℹ️ ✨ 10 records were generated (only showing first 10)
{"schema":{"type":"struct","fields":[{"type":"string","optional":false,"field":"record"}]},"payload":{"record":"cdcd"}}
{"schema":{"type":"struct","fields":[{"type":"string","optional":false,"field":"record"}]},"payload":{"record":"cdcd"}}
{"schema":{"type":"struct","fields":[{"type":"string","optional":false,"field":"record"}]},"payload":{"record":"cdcd"}}
{"schema":{"type":"struct","fields":[{"type":"string","optional":false,"field":"record"}]},"payload":{"record":"cdcd"}}
{"schema":{"type":"struct","fields":[{"type":"string","optional":false,"field":"record"}]},"payload":{"record":"cdcd"}}
{"schema":{"type":"struct","fields":[{"type":"string","optional":false,"field":"record"}]},"payload":{"record":"cdcd"}}
{"schema":{"type":"struct","fields":[{"type":"string","optional":false,"field":"record"}]},"payload":{"record":"cdcd"}}
{"schema":{"type":"struct","fields":[{"type":"string","optional":false,"field":"record"}]},"payload":{"record":"cdcd"}}
{"schema":{"type":"struct","fields":[{"type":"string","optional":false,"field":"record"}]},"payload":{"record":"cdcd"}}
{"schema":{"type":"struct","fields":[{"type":"string","optional":false,"field":"record"}]},"payload":{"record":"cdcd"}}
22:08:26 ❗ topic topic-json-with-schema does not exist !
22:08:26 ℹ️ 📤 producing 10 records to topic topic-json-with-schema
[2023-06-12 20:08:28,031] WARN [Producer clientId=console-producer] Error while fetching metadata with correlation id 1 : {topic-json-with-schema=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient)
22:08:28 ℹ️ 💯 Get number of records in topic topic-json-with-schema
10
```

#### **simple records**

```bash
$ playground topic produce -t topic-string --nb-messages 30 << 'EOF'
Ad et ut pariatur officia eos.
Nesciunt fugit nam libero ut qui itaque sed earum at itaque nesciunt eveniet atque.
Quidem libero quis quod et illum excepturi voluptas et in perspiciatis iusto neque.
Quibusdam commodi explicabo dolores molestiae qui delectus dolorum fugiat molestiae natus assumenda omnis expedita.
Et sunt aut architecto suscipit fugiat qui voluptate iure vel doloremque eum culpa.
Qui enim facilis eos similique aperiam totam eius et at dolor dolores.
Ut sunt quia qui quia consectetur aut reiciendis.
Modi adipisci iusto aut voluptatem dolores laudantium.
Sequi sint quia quibusdam molestias minus et aliquid voluptatum aliquam.
Rerum aut amet quo possimus nihil velit quisquam ut cumque.
Pariatur ad officiis voluptatibus quia vel corporis ea fugit adipisci porro.
EOF
22:09:11 ℹ️ 📢 no known schema could be identified, payload will be sent as raw data
22:09:11 ℹ️ 💫 payload is not single json, one record per line will be sent
22:09:11 ℹ️ ✨ 30 records were generated (only showing first 10)
Ad et ut pariatur officia eos.
Nesciunt fugit nam libero ut qui itaque sed earum at itaque nesciunt eveniet atque.
Quidem libero quis quod et illum excepturi voluptas et in perspiciatis iusto neque.
Quibusdam commodi explicabo dolores molestiae qui delectus dolorum fugiat molestiae natus assumenda omnis expedita.
Et sunt aut architecto suscipit fugiat qui voluptate iure vel doloremque eum culpa.
Qui enim facilis eos similique aperiam totam eius et at dolor dolores.
Ut sunt quia qui quia consectetur aut reiciendis.
Modi adipisci iusto aut voluptatem dolores laudantium.
Sequi sint quia quibusdam molestias minus et aliquid voluptatum aliquam.
Rerum aut amet quo possimus nihil velit quisquam ut cumque.
22:09:13 ❗ topic topic-string does not exist !
22:09:13 ℹ️ 📤 producing 30 records to topic topic-string
[2023-06-12 20:09:15,054] WARN [Producer clientId=console-producer] Error while fetching metadata with correlation id 1 : {topic-string=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient)
22:09:15 ℹ️ 💯 Get number of records in topic topic-string
30
```

#### **with key**

```bash
$ playground topic produce -t topic-json-multiple-lines --nb-messages 10 --key "mykey" << 'EOF'
{"u_name": "scissors", "u_price": 2.75, "u_quantity": 3}
{"u_name": "tape", "u_price": 0.99, "u_quantity": 10}
{"u_name": "notebooks", "u_price": 1.99, "u_quantity": 5}
EOF
22:11:11 ℹ️ 📢 no known schema could be identified, payload will be sent as raw data
22:11:11 ℹ️ 💫 payload is single json, it will be sent as one record
22:11:12 ℹ️ ✨ 30 records were generated (only showing first 10)
{"u_name":"scissors","u_price":2.75,"u_quantity":3}
{"u_name":"tape","u_price":0.99,"u_quantity":10}
{"u_name":"notebooks","u_price":1.99,"u_quantity":5}
{"u_name":"scissors","u_price":2.75,"u_quantity":3}
{"u_name":"tape","u_price":0.99,"u_quantity":10}
{"u_name":"notebooks","u_price":1.99,"u_quantity":5}
{"u_name":"scissors","u_price":2.75,"u_quantity":3}
{"u_name":"tape","u_price":0.99,"u_quantity":10}
{"u_name":"notebooks","u_price":1.99,"u_quantity":5}
{"u_name":"scissors","u_price":2.75,"u_quantity":3}
22:11:14 ❗ topic topic-json-multiple-lines does not exist !
22:11:14 ℹ️ 🗝️ key is set mykey
22:11:14 ℹ️ 📤 producing 30 records to topic topic-json-multiple-lines
[2023-06-12 20:11:15,665] WARN [Producer clientId=console-producer] Error while fetching metadata with correlation id 1 : {topic-json-multiple-lines=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient)
22:11:16 ℹ️ 💯 Get number of records in topic topic-json-multiple-lines
30
```

#### **tombstone**

```bash
$ playground topic produce -t topic-json-multiple-lines --key mykey --tombstone 
22:12:06 ℹ️ ⚰️ Sending tombstone for key mykey in topic topic-json-multiple-lines
```
<!-- tabs:end -->

### 📥 `consume`

Consume topic from beginning without needing to specify any configuration (even the topic name is optional)!

<script async id="asciicast-583918" src="https://asciinema.org/a/583918.js"></script>

### 💯 `get-number-records`

Get number of records in a topic

<script async id="asciicast-583916" src="https://asciinema.org/a/583916.js"></script>

### 📭 `display-consumer-offsets`

Display content of __consumer_offsets topic

### 🔬 `describe`

🔬 Describe topic

<script async id="asciicast-583917" src="https://asciinema.org/a/583917.js"></script>

### 🛡️ `set-schema-compatibility`

Change topic's schema compatibility

```bash
$ playground topic set-schema-compatibility --help
playground topic set-schema-compatibility - 🛡️ Change topic's schema compatibility

== Usage ==
  playground topic set-schema-compatibility [OPTIONS]
  playground topic set-schema-compatibility --help | -h

== Options ==
  --topic, -t TOPIC
    🗳 Topic name

  --compatibility COMPATIBILITY (required)
    Schema Registry compatibility rule
    Allowed: BACKWARD, BACKWARD_TRANSITIVE, FORWARD, FORWARD_TRANSITIVE, FULL, FULL_TRANSITIVE, NONE

  --help, -h
    Show this help
```
<script async id="asciicast-584428" src="https://asciinema.org/a/584428.js"></script>

### 🧞 `display-schema-id-statistics`

Easily identify the usage of different schema versions within a topic.

It makes use of https://github.com/EladLeev/schema-registry-statistics

It only works when plaintext environment is used

<script async id="asciicast-584424" src="https://asciinema.org/a/584424.js"></script>

Example:

```bash
playground topic display-schema-id-statistics 
13:34:27 ℹ️ ✨ --topic flag was not provided, applying command to all topics
13:34:31 ℹ️ ✨ Display statistics of topic test_hdfs, it contains 10 messages
{
  "1": [
    0,
    1,
    2,
    3,
    4,
    5,
    6,
    7,
    8,
    9
  ]
}
```

### 🆕 `create`

Create a topic.

```bash
playground topic create --help
playground topic create - 🆕 Create topic

== Usage ==
  playground topic create [OPTIONS] [ARGUMENTS...]
  playground topic create --help | -h

== Options ==
  --topic, -t TOPIC (required)
    🗳 Topic name

  --nb-partitions NB-PARTITIONS
    Number of partitions for the topic. (default is 1)
    Default: 

  --help, -h
    Show this help

== Arguments ==
  ARGUMENTS...
    Any arguments to be used with kafka-topics --create

Examples
  playground topic create --topic atopic
  playground topic create --topic atopic --nb-partitions 8 --config
  retention.ms=30000
```

### ❌ `delete`

Delete a topic.

```bash
playground topic delete --help
playground topic delete - ❌ Delete topic

== Usage ==
  playground topic delete [OPTIONS]
  playground topic delete --help | -h

== Options ==
  --topic, -t TOPIC (required)
    🗳 Topic name

  --help, -h
    Show this help
```

## 🔮 Kafka commands

Kafka specific commands.

### 📝 `get-properties`

Get properties file from a container. See documentation [here](/how-to-use?id=%f0%9f%93%9d-see-properties-file).

<script async id="asciicast-583919" src="https://asciinema.org/a/583919.js"></script>

### 🔰 `get-all-schemas`

Get all schemas versions for all subjects.

<script async id="asciicast-583920" src="https://asciinema.org/a/583920.js"></script>

```bash
playground get-all-schemas

  🔰 Get all schemas versions for all subjects

== Usage ==
  playground get-all-schemas [OPTIONS]
  playground get-all-schemas --help | -h

== Options ==
  --open, -o
    🔖 Save output to a file and open with text editor set with config.ini
    (default is code)

  --help, -h
    Show this help

Examples
  playground get-all-schemas
```

### 🔢 `get-jmx-metrics`

Get JMX metrics from a component. See documentation [there](/how-to-use?id=%f0%9f%94%a2-jmx-metrics).


## 🐛 Debug commands

Debug specific commands.

### ✨ `enable-remote-debugging`

Enable java remote debugging for container. See documentation [here](/reusables?id=%e2%9c%a8-remote-debugging).

### 🧬 `log-level`

Set log level for any package.

```bash
playground debug log-level --help
playground debug log-level

  🧬 Set log level for any package

== Usage ==
  playground debug log-level COMMAND
  playground debug log-level [COMMAND] --help | -h

== Commands ==
  get   Get log levels
  set   Set log level for specific logger

== Options ==
  --help, -h
    Show this help

Examples
  playground debug log-level get
  playground debug log-level get -p io.confluent.connect.oracle.cdc
  playground debug log-level get --package io.confluent.connect.oracle.cdc
  playground debug log-level set -p io.confluent.connect.oracle.cdc.logging.LogUtils
  -l TRACE
```

### 🎯 `thread-dump`

Take a thread dump with jstack for container (pid 1)

```bash
playground debug thread-dump --help                                     
playground debug thread-dump

  🎯 Take a java thread dump
  
  🔖 It will save output to a file and open with text editor set with config.ini
  (default is code)

== Usage ==
  playground debug thread-dump [OPTIONS]
  playground debug thread-dump --help | -h

== Options ==
  --container, -c CONTAINER
    🐳 Container name
    Default: connect

  --help, -h
    Show this help

Examples
  playground debug thread-dump
  playground debug thread-dump --container broker

```